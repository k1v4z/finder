## ğŸ›’ Best product in e-commerce websites
# ğŸ“„ Overview
This project is designed to crawl product data from Lazada and Sendo, process the data to determine the best product from each e-commerce website, and provide this information through an API. The crawling process is automated to run daily at 11 PM using a Cron Job. The backend is developed using the Express framework.

# âœ¨ Features
- ğŸ•¸ï¸ Data Crawling: Utilizes Puppeteer to scrape product data from Lazada and Sendo.
- ğŸ§® Data Processing: Analyzes the crawled data to identify the best product from each website.
- â° Automation: Implements a Cron Job to automate data crawling every day at 11 PM. If data's product don't exist in database, it will write name of product into ProductCrawl.json and crawl at 11h PM. The more user find product the more data increase
- ğŸŒ API Development: Provides the processed data through an API developed with Express.
# ğŸ› ï¸ Technologies Used
- ğŸ–¥ï¸ Puppeteer: For web scraping and data extraction from Lazada and Sendo.
- ğŸŸ¢ Node.js: JavaScript runtime environment for building the application.
- âš™ï¸ Express: Web framework for building the API.
- â³ Cron: For scheduling automated tasks.
# ğŸš€ Getting Started
- ğŸ“‹ Prerequisites
  - Node.js (v14 or higher)
  - npm (v6 or higher)
# ğŸ“¥ Installation
- Clone the repository: `https://github.com/k1v4z/finder.git`
- Install dependencies: `npm install`
# âš™ï¸ Configuration
- Create .env file: `
  PORT: YOUR_PORT
  HOST: YOUR_HOST
`
- Create ProductCrawl.json file follow this format in src folder: `{"name":["tÃºi chá»‘ng sá»‘c","fuhlen g90","Ã¡o thun","Ã¡o len"]}`
- Create ServiceAccountKey.json in src folder: Get service account follow guide of firebase
# â–¶ï¸ Run
- Run command: `npm run dev`
- Open `Finder.html` and `Open with Live Server`
# Test
- Home <img align="center" src="./images/images.png/"/>
- Show best product <img align="center" src="./images/images2.png/"/>
- List product <img align="center" src="./images/images3.png/"/>
# ğŸ“œ License
This project is licensed under the MIT License - see the LICENSE file for details.
